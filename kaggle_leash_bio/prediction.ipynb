{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu121\n",
      "DGL version: 2.1.0\n",
      "CUDA available in PyTorch: True\n",
      "CUDA available in DGL: False\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#neccessary imports\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "from loguru import logger\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import tensorflow as tf\n",
    "import dgl\n",
    "from dgl import batch as dgl_batch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dgl.nn import GraphConv, GlobalAttentionPooling\n",
    "\n",
    "#wandb.login()\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"DGL version:\", dgl.__version__)\n",
    "print(\"CUDA available in PyTorch:\", torch.cuda.is_available())\n",
    "\n",
    "# Check CUDA support in DGL\n",
    "try:\n",
    "    # Create a simple graph\n",
    "    g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
    "\n",
    "    # Try to move the graph to GPU\n",
    "    g = g.to('cuda')\n",
    "    print(\"CUDA available in DGL: True\")\n",
    "except:\n",
    "    print(\"CUDA available in DGL: False\")\n",
    "print(dgl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_smi(smi: str | list):\n",
    "    r\"\"\" Clean a SMILES string by removing salts and fragments.\n",
    "    Parameters\n",
    "    ----------\n",
    "    smi : str | list\n",
    "        The SMILES string for a molecule. or a list of SMILES strings\n",
    "    Returns\n",
    "    -------\n",
    "    str | list\n",
    "        The cleaned SMILES string.\n",
    "    \"\"\"\n",
    "    if isinstance(smi, list):\n",
    "        return [clean_smi(s) for s in smi]\n",
    "    # Remove [Dy] from smiles\n",
    "    smi = smi.replace(\"[Dy]\", \"\")\n",
    "\n",
    "    # Convert SMILES to a RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        raise ValueError(\"Invalid SMILES string\")\n",
    "    \n",
    "    # Remove any salts or fragments\n",
    "    mol = Chem.RemoveHs(mol)  # Remove explicit hydrogens\n",
    "    fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "    \n",
    "    # Keep the largest fragment\n",
    "    largest_fragment = max(fragments, default=mol, key=lambda m: m.GetNumAtoms())\n",
    "    \n",
    "    # Standardize the molecule\n",
    "    AllChem.Compute2DCoords(largest_fragment)  # Compute 2D coordinates\n",
    "    \n",
    "    # Convert the molecule back to a canonical SMILES string\n",
    "    cleaned_smiles = Chem.MolToSmiles(largest_fragment, canonical=True)\n",
    "    return cleaned_smiles\n",
    "\n",
    "\n",
    "def smiles_to_dgl_graph(smiles: str |list):\n",
    "    r\"\"\" Convert a SMILES string to a DGLGraph.\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str | list\n",
    "        The SMILES string for a molecule. or a list of SMILES strings\n",
    "    Returns\n",
    "    -------\n",
    "    DGLGraph\n",
    "        A DGLGraph object for the molecule.\n",
    "    \"\"\"\n",
    "    if isinstance(smiles, list):\n",
    "        return [smiles_to_dgl_graph(s) for s in smiles]\n",
    "    clean_smiles=clean_smi(smiles)\n",
    "    mol = Chem.MolFromSmiles(clean_smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # Node features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append([\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            atom.GetHybridization(),\n",
    "            atom.GetIsAromatic(),\n",
    "            atom.GetTotalNumHs()\n",
    "        ])\n",
    "    \n",
    "    # Edge features and adjacency list\n",
    "    src, dst = [], []\n",
    "    bond_features = []\n",
    "    for bond in mol.GetBonds():\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        src.append(start)\n",
    "        dst.append(end)\n",
    "        bond_features.append([\n",
    "            int(bond.GetBondTypeAsDouble()), \n",
    "            bond.GetBondType(),\n",
    "            bond.GetIsConjugated(),\n",
    "            bond.IsInRing()\n",
    "        ])\n",
    "    \"\"\"\n",
    "    g = dgl.graph((src, dst))\n",
    "    g.ndata['h'] = torch.tensor(atom_features, dtype=torch.float)\n",
    "    g.edata['h'] = torch.tensor(bond_features, dtype=torch.float)\n",
    "    g= dgl.add_self_loop(g)\n",
    "    return g\n",
    "    \"\"\"\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "    node_features = torch.tensor(atom_features, dtype=torch.float)\n",
    "    edge_features = torch.tensor(bond_features, dtype=torch.float)\n",
    "\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "    return data\n",
    "\n",
    "#create a dictionary with the protein names as keys and the protein sequences as values\n",
    "protein_sequences = {\n",
    "    \"BRD4\": \"NPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVDAVKLNLPDYYKIIKTPMDMGTIKKRLENNYYWNAQECIQDFNTMFTNCYIYNKPGDDIVLMAEALEKLFLQKINELPTEETEIMIVQAKGRGRGRKETGTAKPGVSTVPNTTQASTPPQTQTPQPNPPPVQATPHPFPAVTPDLIVQTPVMTVVPPQPLQTPPPVPPQPQPPPAPAPQPVQSHPPIIAATPQPVKTKKGVKRKADTTTPTTIDPIHEPPSLPPEPKTTKLGQRRESSRPVKPPKKDVPDSQQHPAPEKSSKVSEQLKCCSGILKEMFAKKHAAYAWPFYKPVDVEALGLHDYCDIIKHPMDMSTIKSKLEAREYRDAQEFGADVRLMFSNCYKYNPPDHEVVAMARKLQDVFEMRFAKMPDE\",\n",
    "    \"sEH\": \"TLRAAVFDLDGVLALPAVFGVLGRTEEALALPRGLLNDAFQKGGPEGATTRLMKGEITLSQWIPLMEENCRKCSETAKVCLPKNFSIKEIFDKAISARKINRPMLQAALMLRKKGFTTAILTNTWLDDRAERDGLAQLMCELKMHFDFLIESCQVGMVKPEPQIYKFLLDTLKASPSEVVFLDDIGANLKPARDLGMVTILVQDTDTALKELEKVTGIQLLNTPAPLPTSCNPSDMSHGYVTVKPRVRLHFVELGSGPAVCLCHGFPESWYSWRYQIPALAQAGYRVLAMDMKGYGESSAPPEIEEYCMEVLCKEMVTFLDKLGLSQAVFIGHDWGGMLVWYMALFYPERVRAVASLNTPFIPANPNMSPLESIKANPVFDYQLYFQEPGVAEAELEQNLSRTFKSLFRASDESVLSMHKVCEAGGLFVNSPEEPSLSRMVTEEEIQFYVQQFKKSGFRGPLNWYRNMERNWKWACKSLGRKILIPALMVTAEKDFVLVPQMSQHMEDWIPHLKRGHIEDCGHWTQMDKPTEVNQILIKWLDSDARNPPVVSKM\",\n",
    "    \"HSA\": \"DAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL\",\n",
    "}\n",
    "\n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "\n",
    "\n",
    "def one_hot_encode_sequence(sequence, aa_to_index=aa_to_index):\n",
    "    one_hot_encoded = np.zeros((len(sequence), len(amino_acids)), dtype=np.float32)\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in aa_to_index:\n",
    "            one_hot_encoded[i, aa_to_index[aa]] = 1.0\n",
    "    return one_hot_encoded\n",
    "\n",
    "# Function to generate one-hot encoded features for proteins\n",
    "def generate_protein_one_hot_features(protein_sequences):\n",
    "    features = {}\n",
    "    for protein_name, sequence in protein_sequences.items():\n",
    "        one_hot_features = one_hot_encode_sequence(sequence)\n",
    "        features[protein_name] = one_hot_features\n",
    "    return features\n",
    "\n",
    "def protein_to_features(protein_seq: str):\n",
    "    #one hot encode the amino acid composition\n",
    "    one_hot_encoded = one_hot_encode_sequence(protein_seq)\n",
    "    amino_acid_composition = torch.tensor(one_hot_encoded, dtype=torch.float)\n",
    "    # Hydrophobicity\n",
    "    hydrophobicity = [0] * len(protein_seq)\n",
    "    for i, amino_acid in enumerate(protein_seq):\n",
    "        if amino_acid in ['A', 'I', 'L', 'M', 'F', 'W', 'V']:\n",
    "            hydrophobicity[i] = 1\n",
    "    hydrophobicity = torch.tensor(hydrophobicity, dtype=torch.float).unsqueeze(1)\n",
    "    # Charge\n",
    "    charge = [0] * len(protein_seq)\n",
    "    for i, amino_acid in enumerate(protein_seq):\n",
    "        if amino_acid in ['K', 'R']:\n",
    "            charge[i] = 1\n",
    "        elif amino_acid in ['D', 'E']:\n",
    "            charge[i] = -1\n",
    "    charge = torch.tensor(charge, dtype=torch.float).unsqueeze(1)\n",
    "    # Concatenate features\n",
    "    protein_features = torch.cat((amino_acid_composition, hydrophobicity, charge), dim=1)\n",
    "    return protein_features\n",
    "\n",
    "def protein_to_graph(protein_seq, protein_features, neighbor_distance=3):\n",
    "    node_features = protein_features\n",
    "    edge_index = []\n",
    "    for i in range(len(protein_seq)):\n",
    "        for j in range(i + 1, min(i + neighbor_distance + 1, len(protein_seq))):\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "\n",
    "    data = Data(x=node_features, edge_index=edge_index)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "class ProteinLigandGCN(torch.nn.Module):\n",
    "    def __init__(self, protein_feature_dim, ligand_feature_dim, hidden_dim, output_dim,dropout=0.2):\n",
    "        super(ProteinLigandGCN, self).__init__()\n",
    "        # Initialize GCN layers for protein\n",
    "        self.protein_conv1 = GCNConv(protein_feature_dim, hidden_dim)\n",
    "        self.protein_conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Initialize GCN layers for ligand\n",
    "        self.ligand_conv1 = GCNConv(ligand_feature_dim, hidden_dim)\n",
    "        self.ligand_conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected layers for each graph after GCN layers\n",
    "        self.protein_fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ligand_fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Final fully connected layer after combining\n",
    "        self.final_fc = nn.Linear(2 * hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, protein_data, ligand_data):\n",
    "        # Protein graph processing\n",
    "        protein_graph, protein_features = protein_data\n",
    "        ligand_graph, ligand_features = ligand_data\n",
    "        \n",
    "        # Apply GCN layers to protein graph\n",
    "        protein_x = F.relu(self.protein_conv1(protein_features, protein_graph.edge_index))\n",
    "        protein_x = self.dropout1(protein_x)\n",
    "        protein_x = F.relu(self.protein_conv2(protein_x, protein_graph.edge_index))\n",
    "        protein_x = self.dropout2(protein_x)\n",
    "        \n",
    "        # Pooling (choose one of the following or implement your own)\n",
    "        #protein_output = global_add_pool(protein_x, protein_graph.batch)  # Global sum pooling\n",
    "        protein_output = global_mean_pool(protein_x, protein_graph.batch)  # Global mean pooling\n",
    "        # protein_output = global_max_pool(protein_x, protein_graph.batch)  # Global max pooling\n",
    "        \n",
    "        protein_output = F.relu(self.protein_fc(protein_output))\n",
    "\n",
    "        # Apply GCN layers to ligand graph\n",
    "        ligand_x = F.relu(self.ligand_conv1(ligand_features, ligand_graph.edge_index))\n",
    "        ligand_x = self.dropout1(ligand_x)\n",
    "        ligand_x = F.relu(self.ligand_conv2(ligand_x, ligand_graph.edge_index))\n",
    "        ligand_x = self.dropout2(ligand_x)\n",
    "        \n",
    "        # Pooling (choose one of the following or implement your own)\n",
    "        #ligand_output = global_add_pool(ligand_x, ligand_graph.batch)  # Global sum pooling\n",
    "        ligand_output = global_mean_pool(ligand_x, ligand_graph.batch)  # Global mean pooling\n",
    "        # ligand_output = global_max_pool(ligand_x, ligand_graph.batch)  # Global max pooling\n",
    "        \n",
    "        ligand_output = F.relu(self.ligand_fc(ligand_output))\n",
    "\n",
    "        # Combine protein and ligand outputs\n",
    "        combined_output = torch.cat((protein_output, ligand_output), dim=1)\n",
    "        final_output = self.final_fc(combined_output)\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "class ProteinLigandDataset(Dataset):\n",
    "    def __init__(self, data, protein_sequences, transform=None):\n",
    "        self.data = data\n",
    "        self.protein_sequences = protein_sequences\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        protein_name = self.data.iloc[idx][\"protein_name\"]\n",
    "        molecule_smiles = self.data.iloc[idx][\"molecule_smiles\"]\n",
    "        #check if there is a label in the data\n",
    "        if \"binds\" in self.data.columns:\n",
    "            label = self.data.iloc[idx][\"binds\"]\n",
    "        else:\n",
    "            label = self.data.iloc[idx][\"id\"]\n",
    "        #label = self.data.iloc[idx][\"binds\"]\n",
    "        \n",
    "        protein_graph = protein_to_graph(self.protein_sequences[protein_name], protein_to_features(self.protein_sequences[protein_name]))\n",
    "        smiles_graph = smiles_to_dgl_graph(molecule_smiles)\n",
    "        \"\"\"\n",
    "        protein_features = protein_graph.ndata['h']\n",
    "        smiles_features = smiles_graph.ndata['h']\n",
    "                    'protein_features': protein_features,\n",
    "                                'smiles_features': smiles_features,\n",
    "        \"\"\"\n",
    "        sample = {\n",
    "            'protein_graph': protein_graph,\n",
    "            'smiles_graph': smiles_graph,\n",
    "            'label': label\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    protein_graphs = [item['protein_graph'] for item in batch]\n",
    "    #protein_features = [item['protein_features'] for item in batch]\n",
    "    smiles_graphs = [item['smiles_graph'] for item in batch]\n",
    "    #smiles_features = [item['smiles_features'] for item in batch]\n",
    "    labels = torch.tensor([item['label'] for item in batch], dtype=str)\n",
    "    \"\"\"\n",
    "    batched_protein_graph = dgl_batch(protein_graphs)\n",
    "    batched_smiles_graph = dgl_batch(smiles_graphs)\n",
    "    \n",
    "    batched_protein_features = torch.cat(protein_features)\n",
    "    batched_smiles_features = torch.cat(smiles_features)\n",
    "    \"\"\"\n",
    "    batched_protein_graph = Batch.from_data_list(protein_graphs)\n",
    "    batched_smiles_graph = Batch.from_data_list(smiles_graphs)\n",
    "    return {\n",
    "        'protein_graph': batched_protein_graph,\n",
    "        'smiles_graph': batched_smiles_graph,\n",
    "        'label': labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=ds.dataset(source=\"../../../data/test.parquet\", format=\"parquet\").to_table().to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-05 12:36:36.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mkeys in checkpoint: dict_keys(['epoch', 'odel_state_dict', 'optimizer_state_dict', 'average_train_loss', 'average_val_loss'])\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-05 12:36:36.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mmodel state dict: OrderedDict([('protein_conv1.bias', tensor([-0.6005, -0.4973, -0.6663, -0.4601, -0.6563, -0.4538, -0.4558, -0.4845,\n",
      "        -0.4897, -0.4733, -0.5136, -0.6005, -0.6004, -0.6003, -0.6000, -0.6873,\n",
      "        -0.6004, -0.4847, -0.5994, -0.4775, -0.6601, -0.6005, -0.6004, -0.6607,\n",
      "        -0.5992, -0.6000, -0.4971, -0.5973, -0.4891, -0.5065, -0.4617, -0.6002,\n",
      "        -0.4900, -0.6004, -0.4612, -0.4735, -0.6004, -0.4861, -0.6005, -0.6616,\n",
      "        -0.4834, -0.6005, -0.6004, -0.4855, -0.7409, -0.6560, -0.6005, -0.6796,\n",
      "        -0.4818, -0.5989, -0.6005, -0.4376, -0.6004, -0.4918, -0.6003, -0.4753,\n",
      "        -0.4994, -0.6563, -0.6004, -0.4780, -0.6004, -0.6003, -0.5180, -0.7271,\n",
      "        -0.4879, -0.4654, -0.5180, -0.4836, -0.6004, -0.4936, -0.6001, -0.6004,\n",
      "        -0.6002, -0.6002, -0.6005, -0.4758, -0.5065, -0.4954, -0.6004, -0.4627,\n",
      "        -0.6002, -0.4680, -0.5998, -0.4676, -0.5988, -0.6004, -0.4801, -0.6005,\n",
      "        -0.7196, -0.6562, -0.4841, -0.6005, -0.4913, -0.5087, -0.6593, -0.4771,\n",
      "        -0.5996, -0.4891, -0.4991, -0.6004, -0.6555, -0.4874, -0.6004, -0.5950,\n",
      "        -0.4812, -0.5045, -0.4580, -0.5997, -0.6003, -0.6003, -0.6004, -0.4744,\n",
      "        -0.6005, -0.6005, -0.4955, -0.5997, -0.4738, -0.6003, -0.5066, -0.4490,\n",
      "        -0.4878, -0.5252, -0.6582, -0.6004, -0.4823, -0.4756, -0.4679, -0.5332],\n",
      "       device='cuda:0')), ('protein_conv1.lin.weight', tensor([[-0.7760, -0.7246, -0.6250,  ..., -0.4778, -0.4126,  0.6145],\n",
      "        [-0.5945, -0.4276, -0.4204,  ..., -0.6876, -0.4522, -0.4876],\n",
      "        [-0.7561, -0.7104, -0.7305,  ..., -0.7239, -0.7235, -0.2958],\n",
      "        ...,\n",
      "        [-0.3689, -0.5163, -0.4137,  ..., -0.6561, -0.6103,  0.2446],\n",
      "        [-0.3195, -0.6371, -0.4417,  ..., -0.6255, -0.6113,  0.4432],\n",
      "        [-0.4093, -0.6444, -0.4064,  ..., -0.5027, -0.4575, -0.2915]],\n",
      "       device='cuda:0')), ('protein_conv2.bias', tensor([-0.6005, -0.5172, -0.5996, -0.6005, -0.5973, -0.6005, -0.6005, -0.6004,\n",
      "        -0.5509, -0.5713, -0.5518, -0.6005, -0.5827, -0.6005, -0.6005, -0.6005,\n",
      "        -0.4573, -0.5997, -0.5304, -0.6000, -0.6003, -0.6005, -0.4560, -0.5063,\n",
      "        -0.5207, -0.5402, -0.2821, -0.4643, -0.4879, -0.5750, -0.5456, -0.5927,\n",
      "        -0.5182, -0.5776, -0.6005, -0.6004, -0.6005, -0.5997, -0.6003, -0.6005,\n",
      "        -0.5966, -0.2534, -0.6002, -0.5878, -0.6003, -0.5663, -0.5769, -0.5249,\n",
      "        -0.6022, -0.6005, -0.2529, -0.6005, -0.5204, -0.6087, -0.5372, -0.6005,\n",
      "        -0.6794, -0.5606, -0.6005, -0.4577, -0.5346, -0.5959, -0.5697, -0.6005,\n",
      "        -0.6004, -0.6000, -0.6003, -0.5990, -0.5362, -0.5643, -0.6004, -0.6004,\n",
      "        -0.6005, -0.5945, -0.6005, -0.6005, -0.5375, -0.5580, -0.6003, -0.6060,\n",
      "        -0.6000, -0.4894, -0.6005, -0.5391, -0.6004, -0.5985, -0.5098, -0.6005,\n",
      "        -0.5366, -0.6004, -0.5718, -0.5595, -0.5197, -0.5999, -0.4588, -0.4873,\n",
      "        -0.5529, -0.6005, -0.6005, -0.5778, -0.6005, -0.5008, -0.4559, -0.6002,\n",
      "        -0.6005, -0.5940, -0.6005, -0.4914, -0.6005, -0.5078, -0.5979, -0.6005,\n",
      "        -0.4910, -0.6531, -0.5158, -0.6005, -0.6004, -0.6002, -0.6004, -0.6005,\n",
      "        -0.6080, -0.4890, -0.5788, -0.6005, -0.6034, -0.5974, -0.5500, -0.6706],\n",
      "       device='cuda:0')), ('protein_conv2.lin.weight', tensor([[-0.6436, -0.5686, -0.5648,  ..., -0.6090, -0.5695, -0.6528],\n",
      "        [ 0.6842, -0.6083, -0.4023,  ..., -0.3400, -0.5895, -0.4289],\n",
      "        [-0.5197, -0.4682, -0.3794,  ..., -0.4459, -0.5074, -0.6598],\n",
      "        ...,\n",
      "        [-0.1463, -0.3703, -0.0417,  ..., -0.2830, -0.1706, -0.6595],\n",
      "        [ 0.6815, -0.4442, -0.5062,  ..., -0.4795, -0.4666, -0.3942],\n",
      "        [-0.3720, -0.5565,  0.6591,  ..., -0.3984, -0.4135, -0.5307]],\n",
      "       device='cuda:0')), ('ligand_conv1.bias', tensor([ 0.0000,  0.0000,  0.0000, -0.6503, -0.6005, -0.5998, -0.5961, -0.5994,\n",
      "         0.0000, -0.7808, -0.4536,  0.0000, -0.6001, -0.5917, -0.6804,  0.0000,\n",
      "        -0.5990, -0.6000, -0.6690,  0.0000, -0.5972,  0.0000, -0.6563, -0.7476,\n",
      "        -0.5993, -0.6850, -0.7160, -0.6003, -0.7228, -0.4143,  0.0000, -0.1685,\n",
      "        -0.7617, -0.6004,  0.0000,  0.0000,  0.0000, -0.5989,  0.0000, -0.6005,\n",
      "         0.0000,  0.0000, -0.6560,  0.0000, -0.6005,  0.0000, -0.5699, -0.7271,\n",
      "         0.0000, -0.6005,  0.0000,  0.0000, -0.6005, -0.7550, -0.6004, -0.6005,\n",
      "         0.0000, -0.6005, -0.6599,  0.0000, -0.6002, -0.6563, -0.5998, -0.5997,\n",
      "         0.0000,  0.0000, -0.6005, -0.4734, -0.6005,  0.0000, -0.6003, -0.6174,\n",
      "         0.0000, -0.6053,  0.0000, -0.6004, -0.7180, -0.5450, -0.6350, -0.6425,\n",
      "        -0.6982,  0.0000, -0.7366, -0.5973, -0.5928, -0.6055, -0.6005, -0.7767,\n",
      "        -0.6265,  0.0000,  0.0000,  0.0000,  0.0000, -0.7735,  0.0000, -0.6270,\n",
      "         0.0000, -0.7262, -0.5848, -0.6004,  0.0000, -0.7164, -0.2719, -0.7562,\n",
      "        -0.6005, -0.5857, -0.6209, -0.6005,  0.0000,  0.0000, -0.5232, -0.6005,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6561, -0.5992,  0.0000,\n",
      "        -0.7626, -0.7044,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6004],\n",
      "       device='cuda:0')), ('ligand_conv1.lin.weight', tensor([[-1.5570e-01,  1.1672e-01, -4.9565e-02, -4.5777e-02,  1.7880e-01,\n",
      "         -2.1328e-02],\n",
      "        [-3.3207e-03, -3.3532e-02,  1.8310e-01, -1.0567e-01, -4.9210e-02,\n",
      "         -1.3585e-01],\n",
      "        [-1.4264e-01, -6.9343e-02, -7.4704e-02,  1.4266e-01,  1.4791e-02,\n",
      "         -1.1068e-01],\n",
      "        [-4.9060e-01, -8.0835e-01, -5.5862e-01, -6.8598e-01, -5.0659e-01,\n",
      "         -4.7519e-01],\n",
      "        [-6.4900e-01, -4.1211e-01, -7.1564e-01, -4.0044e-01, -6.5026e-01,\n",
      "         -5.4919e-01],\n",
      "        [-6.8390e-01, -6.0339e-01,  2.9296e-02, -4.5875e-01, -7.7356e-01,\n",
      "         -4.7798e-01],\n",
      "        [-5.8614e-01, -4.9613e-01, -6.1927e-01, -5.9297e-01, -4.7818e-01,\n",
      "         -5.3239e-01],\n",
      "        [-5.5614e-01, -6.7703e-01, -8.3659e-02, -7.9858e-01, -7.5302e-01,\n",
      "         -3.9824e-01],\n",
      "        [-1.9700e-01, -2.5123e-02,  1.3096e-01, -1.7835e-01,  1.9732e-01,\n",
      "          3.7934e-02],\n",
      "        [-5.7793e-01, -7.0625e-01, -7.2435e-01, -7.6509e-01, -9.3818e-01,\n",
      "         -7.7495e-01],\n",
      "        [-6.1763e-01, -4.5717e-01,  1.3504e-01, -5.8416e-01, -6.4758e-01,\n",
      "          1.5272e-02],\n",
      "        [-1.2052e-01,  1.7645e-01,  9.4583e-02, -2.0882e-02,  4.4433e-02,\n",
      "          8.3366e-03],\n",
      "        [-6.1197e-01, -4.0552e-01,  4.0400e-01, -4.2118e-01, -6.1027e-01,\n",
      "         -6.0081e-01],\n",
      "        [-7.2492e-01, -5.2175e-01,  1.0520e-01, -5.3604e-01,  6.0154e-02,\n",
      "         -4.3004e-01],\n",
      "        [-4.7627e-01, -7.7131e-01, -9.7293e-01, -5.8949e-01, -7.6240e-01,\n",
      "         -8.5697e-01],\n",
      "        [-5.1875e-02, -7.9800e-02, -4.3992e-02, -5.9719e-02, -3.1421e-02,\n",
      "          8.4150e-02],\n",
      "        [-4.7368e-01, -7.5338e-01, -2.0119e-01, -8.0503e-01, -6.4210e-01,\n",
      "         -6.3121e-01],\n",
      "        [-5.4856e-01, -5.0701e-01,  3.9042e-01, -6.1599e-01, -5.3903e-01,\n",
      "         -4.1198e-01],\n",
      "        [-4.9474e-01, -6.7652e-01, -6.9900e-01, -6.1639e-01, -4.6310e-01,\n",
      "         -6.2960e-01],\n",
      "        [-1.6622e-01, -1.9370e-01,  2.1933e-02,  8.6372e-02,  1.9311e-01,\n",
      "         -2.0005e-01],\n",
      "        [-7.5999e-01, -5.0072e-01, -6.6439e-01, -4.0167e-01, -4.2645e-01,\n",
      "         -5.9227e-01],\n",
      "        [-4.8831e-02, -4.8011e-02, -6.7185e-02,  8.0524e-02,  8.3050e-02,\n",
      "         -1.9048e-01],\n",
      "        [-5.5520e-01, -4.8677e-01, -6.1781e-01, -5.2287e-01, -7.9691e-01,\n",
      "         -7.0110e-01],\n",
      "        [-6.4945e-01, -9.4272e-01, -9.2307e-01, -5.7320e-01, -5.4469e-01,\n",
      "         -8.2607e-01],\n",
      "        [-5.8027e-01, -4.9574e-01, -6.5415e-01, -6.7147e-01, -7.0511e-01,\n",
      "         -4.7772e-01],\n",
      "        [-5.0884e-01, -4.8415e-01, -8.3827e-01, -7.6092e-01, -8.8080e-01,\n",
      "         -8.5769e-01],\n",
      "        [-5.2788e-01, -8.0914e-01, -6.6868e-01, -6.7253e-01, -8.4852e-01,\n",
      "         -4.8741e-01],\n",
      "        [-6.3862e-01, -4.8077e-01, -5.5473e-01, -4.7753e-01, -5.3679e-01,\n",
      "         -7.3024e-01],\n",
      "        [-5.1791e-01, -6.5072e-01, -8.8428e-01, -5.7238e-01, -6.6346e-01,\n",
      "         -8.5177e-01],\n",
      "        [-5.5955e-01, -3.5220e-01, -4.8975e-01, -2.3813e-01, -7.0914e-01,\n",
      "         -3.6204e-01],\n",
      "        [-1.9381e-01, -1.1227e-01, -5.5697e-02,  1.3177e-01, -9.6961e-03,\n",
      "          2.1130e-01],\n",
      "        [-2.7063e-01, -5.7612e-02, -4.3270e-01, -1.2029e-01, -2.5209e-01,\n",
      "         -1.0620e-01],\n",
      "        [-5.9895e-01, -6.9952e-01, -7.1984e-01, -5.5627e-01, -7.1686e-01,\n",
      "         -6.8451e-01],\n",
      "        [-4.8546e-01, -6.2022e-01, -6.6496e-01, -8.0879e-01, -6.4894e-01,\n",
      "         -7.2780e-01],\n",
      "        [-1.3943e-01,  9.3885e-02,  3.9875e-02, -8.9934e-02, -7.7975e-02,\n",
      "          1.5059e-02],\n",
      "        [-2.2239e-02,  8.7032e-02, -1.8311e-01, -7.0364e-02, -1.5449e-01,\n",
      "         -1.0238e-03],\n",
      "        [-9.0448e-02, -1.1663e-01,  2.7695e-02,  1.0516e-01,  1.1032e-01,\n",
      "         -3.5507e-03],\n",
      "        [-6.0456e-01, -5.7475e-01, -6.8542e-01, -5.0406e-01, -7.0386e-01,\n",
      "         -8.1364e-01],\n",
      "        [-6.3453e-02, -2.1072e-01, -1.4539e-01, -8.9062e-02, -3.1392e-02,\n",
      "          4.3714e-02],\n",
      "        [-6.2592e-01, -4.6117e-01, -5.9499e-01, -5.1358e-01, -4.9843e-01,\n",
      "         -4.7978e-01],\n",
      "        [-1.6880e-01, -1.1798e-01, -4.5173e-02,  9.5287e-02,  1.8299e-01,\n",
      "         -1.8421e-01],\n",
      "        [ 1.0572e-02, -7.2579e-02, -2.0846e-01, -1.8424e-01,  2.0430e-01,\n",
      "         -6.3063e-02],\n",
      "        [-5.0738e-01, -5.0025e-01, -4.6224e-01, -4.5486e-01, -5.0530e-01,\n",
      "         -4.4843e-01],\n",
      "        [-1.9904e-01,  1.6854e-02, -1.0440e-01,  1.5986e-01,  2.0514e-01,\n",
      "          1.7770e-01],\n",
      "        [-7.6706e-01, -4.1833e-01, -6.0370e-01, -4.1193e-01, -6.3263e-01,\n",
      "         -6.2289e-01],\n",
      "        [-3.8481e-02,  7.3414e-02, -4.8610e-02, -1.1008e-01, -7.8816e-02,\n",
      "          1.8824e-01],\n",
      "        [-6.0213e-01, -5.4470e-01, -9.9536e-01, -4.8492e-01, -7.0901e-01,\n",
      "         -7.6208e-01],\n",
      "        [-5.2891e-01, -7.5452e-01, -9.8710e-01, -5.8954e-01, -9.2373e-01,\n",
      "         -7.4745e-01],\n",
      "        [-1.5053e-01, -3.5203e-02, -1.9928e-01, -1.7682e-02,  6.9943e-02,\n",
      "          1.2663e-02],\n",
      "        [-5.9144e-01, -4.6543e-01, -4.8382e-01, -6.2663e-01, -7.9203e-01,\n",
      "         -3.9064e-01],\n",
      "        [-6.2975e-02,  2.9494e-02,  2.0633e-01, -7.8392e-02,  9.3657e-02,\n",
      "          1.9807e-01],\n",
      "        [-1.7846e-01, -1.2768e-01,  1.7718e-01, -1.9782e-01,  1.2019e-01,\n",
      "          8.2786e-02],\n",
      "        [-6.3627e-01, -4.0873e-01, -7.9112e-01, -4.4896e-01, -7.6215e-01,\n",
      "         -4.4664e-01],\n",
      "        [-6.7673e-01, -6.5963e-01, -9.4168e-01, -7.1284e-01, -6.2982e-01,\n",
      "         -8.2689e-01],\n",
      "        [-6.4167e-01, -4.0591e-01, -7.6927e-01, -4.7004e-01, -7.2418e-01,\n",
      "         -6.4478e-01],\n",
      "        [-5.5859e-01, -4.6160e-01, -6.0959e-01, -6.4954e-01, -7.6272e-01,\n",
      "         -5.1893e-01],\n",
      "        [-1.0755e-01,  5.4679e-02, -1.2278e-01, -3.4559e-02, -1.7776e-01,\n",
      "         -1.1070e-01],\n",
      "        [-4.7239e-01, -5.6028e-01, -7.1386e-01, -6.2604e-01, -4.1285e-01,\n",
      "         -7.8902e-01],\n",
      "        [-4.9316e-01, -8.5925e-01, -7.2788e-01, -5.0692e-01, -5.1292e-01,\n",
      "         -6.1213e-01],\n",
      "        [-1.4768e-01,  6.2753e-02, -1.3049e-01,  1.2886e-01, -1.8302e-01,\n",
      "         -1.9560e-01],\n",
      "        [-5.1450e-01, -6.3797e-01, -6.8996e-01, -5.6549e-01, -6.6837e-01,\n",
      "         -6.8985e-01],\n",
      "        [-6.1144e-01, -7.7808e-01, -6.5656e-01, -5.8086e-01, -4.4642e-01,\n",
      "         -2.8464e-01],\n",
      "        [-5.6543e-01, -7.5768e-01,  5.7216e-01, -5.9822e-01, -4.5701e-01,\n",
      "         -6.5589e-01],\n",
      "        [-6.8010e-01, -4.5720e-01,  9.4173e-02, -5.9395e-01, -1.2068e-01,\n",
      "         -5.0628e-01],\n",
      "        [-6.9073e-02,  1.3243e-01,  4.0577e-02, -1.3120e-01,  1.0880e-01,\n",
      "         -2.1116e-01],\n",
      "        [-1.2882e-01, -1.4508e-01, -7.3454e-02, -1.2396e-01,  1.3757e-02,\n",
      "          8.4215e-02],\n",
      "        [-4.8520e-01, -7.3331e-01, -6.8777e-01, -6.6878e-01, -4.7680e-01,\n",
      "         -6.7924e-01],\n",
      "        [-4.4208e-01, -6.1561e-01, -6.3132e-01, -5.5624e-01, -3.5344e-01,\n",
      "         -6.6585e-01],\n",
      "        [-5.0713e-01, -7.7367e-01, -5.1305e-01, -6.5032e-01, -4.3481e-01,\n",
      "          6.5222e-01],\n",
      "        [-1.2149e-01, -9.7380e-02,  6.2935e-02, -7.1727e-02,  5.1106e-02,\n",
      "          5.4481e-02],\n",
      "        [-6.0642e-01, -4.6595e-01,  5.5318e-01, -5.6174e-01, -4.8071e-01,\n",
      "         -6.3022e-01],\n",
      "        [-5.3349e-01, -5.0195e-01, -9.4094e-01, -7.5710e-01, -7.2733e-01,\n",
      "         -4.1176e-01],\n",
      "        [-1.4594e-01,  1.2161e-01,  3.5789e-02, -1.6462e-02, -4.5579e-02,\n",
      "          1.6039e-01],\n",
      "        [-6.3341e-01, -5.2131e-01, -9.5597e-01, -5.9776e-01, -5.3449e-01,\n",
      "         -6.8386e-01],\n",
      "        [-1.1448e-01,  8.4365e-02, -8.7220e-03, -9.0649e-02,  3.4856e-02,\n",
      "          1.7015e-01],\n",
      "        [-5.4227e-01, -8.0913e-01, -9.0598e-02, -6.0432e-01, -7.5531e-01,\n",
      "         -4.9061e-01],\n",
      "        [-5.2052e-01, -8.5258e-01, -6.8960e-01, -6.7896e-01, -7.6806e-01,\n",
      "         -6.9046e-01],\n",
      "        [-5.3701e-01, -4.8406e-01, -8.2418e-01, -4.8700e-01, -7.2646e-01,\n",
      "         -4.9967e-01],\n",
      "        [-6.0601e-01, -4.9362e-01, -5.0415e-01, -6.4781e-01, -6.9737e-01,\n",
      "         -7.7076e-01],\n",
      "        [-4.5770e-01, -8.2102e-01, -6.2834e-01, -7.9991e-01, -6.0587e-01,\n",
      "         -4.7534e-01],\n",
      "        [-5.9687e-01, -5.4640e-01, -7.4883e-01, -7.4447e-01, -8.9016e-01,\n",
      "         -7.9404e-01],\n",
      "        [-1.3757e-01, -6.6980e-02,  1.5577e-01,  9.4902e-02, -9.6766e-03,\n",
      "         -9.0393e-02],\n",
      "        [-6.6359e-01, -5.3045e-01, -1.1599e+00, -6.2549e-01, -6.5882e-01,\n",
      "         -9.3907e-01],\n",
      "        [-7.0533e-01, -5.1817e-01,  1.7225e-02, -5.7243e-01,  8.3856e-02,\n",
      "         -3.9519e-01],\n",
      "        [-5.7400e-01, -6.6735e-01, -5.0779e-02, -7.3628e-01, -5.4151e-01,\n",
      "         -8.8189e-02],\n",
      "        [-6.2402e-01, -4.0757e-01, -6.7433e-01, -6.6311e-01, -5.0692e-01,\n",
      "         -5.3460e-01],\n",
      "        [-4.9712e-01, -6.4430e-01, -5.2706e-01, -4.7029e-01, -6.3730e-01,\n",
      "         -7.1934e-01],\n",
      "        [-6.3455e-01, -8.0691e-01, -9.5460e-01, -6.7386e-01, -9.1223e-01,\n",
      "         -7.5905e-01],\n",
      "        [-5.7760e-01, -6.2010e-01, -6.0901e-01, -5.5962e-01, -7.8925e-01,\n",
      "         -7.1078e-01],\n",
      "        [-1.8621e-01, -1.1800e-01,  3.0819e-03, -2.0939e-01, -1.6359e-02,\n",
      "          1.7100e-01],\n",
      "        [-1.5711e-01, -1.7033e-01,  1.6538e-01,  9.0006e-02, -1.6620e-01,\n",
      "         -8.8267e-02],\n",
      "        [-1.0590e-01, -2.3973e-02,  2.0990e-01, -1.7043e-01, -2.0466e-01,\n",
      "         -9.6891e-02],\n",
      "        [-1.5077e-01,  6.0678e-02, -4.3783e-02,  1.9346e-02,  9.9678e-02,\n",
      "          1.4244e-01],\n",
      "        [-5.8972e-01, -8.5190e-01, -6.9233e-01, -6.8749e-01, -7.5286e-01,\n",
      "         -9.6055e-01],\n",
      "        [-1.5070e-02,  4.1187e-02,  1.3328e-01, -1.1246e-01, -1.5780e-01,\n",
      "          9.9023e-02],\n",
      "        [-5.4050e-01, -4.7497e-01, -7.1392e-01, -8.2118e-01, -6.1040e-01,\n",
      "         -6.4197e-01],\n",
      "        [-1.3331e-01,  3.2777e-02,  9.1464e-02, -2.0579e-01, -1.5934e-03,\n",
      "          2.0609e-01],\n",
      "        [-6.1331e-01, -6.3237e-01, -7.6285e-01, -5.9192e-01, -7.3992e-01,\n",
      "         -8.6092e-01],\n",
      "        [-4.6577e-01, -7.1854e-01, -7.4178e-01, -5.9853e-01, -4.9575e-01,\n",
      "         -4.9243e-01],\n",
      "        [-5.1066e-01, -4.5641e-01, -5.0181e-01, -7.5409e-01, -6.4979e-01,\n",
      "         -5.0556e-01],\n",
      "        [-2.0107e-02, -6.0278e-02,  1.2984e-01, -2.1261e-02, -1.8362e-01,\n",
      "         -4.4203e-02],\n",
      "        [-5.8091e-01, -5.6892e-01, -8.7882e-01, -6.3303e-01, -5.9715e-01,\n",
      "         -6.9774e-01],\n",
      "        [-2.7366e-01, -1.7964e-01,  1.0344e-01, -4.3279e-01, -1.8500e-01,\n",
      "         -9.2771e-02],\n",
      "        [-5.0302e-01, -9.6970e-01, -8.0885e-01, -8.1794e-01, -6.3908e-01,\n",
      "         -7.0915e-01],\n",
      "        [-6.5865e-01, -4.9551e-01, -4.9277e-01, -4.9896e-01, -7.3490e-01,\n",
      "         -4.8410e-01],\n",
      "        [-5.1644e-01, -7.9684e-01, -7.5335e-01, -4.8065e-01, -5.9054e-01,\n",
      "         -5.9828e-01],\n",
      "        [-6.0519e-01, -6.7040e-01, -8.6539e-01, -5.0618e-01, -7.0567e-01,\n",
      "         -4.7741e-01],\n",
      "        [-5.3223e-01, -4.9027e-01, -5.3629e-01, -7.1255e-01, -4.3924e-01,\n",
      "         -8.1038e-01],\n",
      "        [-1.9681e-01,  1.8805e-02, -1.0815e-01, -1.7357e-01, -9.1292e-02,\n",
      "         -8.7252e-02],\n",
      "        [-1.7410e-01,  1.9650e-01,  3.1213e-02, -2.6017e-02, -1.7191e-01,\n",
      "          1.2942e-01],\n",
      "        [-5.6946e-01, -7.0258e-01, -6.5709e-01, -3.7986e-01, -5.8756e-01,\n",
      "         -5.1720e-01],\n",
      "        [-4.4043e-01, -6.0477e-01, -7.2328e-01, -7.7367e-01, -5.9450e-01,\n",
      "         -6.9477e-01],\n",
      "        [-2.0374e-01, -3.2947e-02, -3.7155e-02, -3.3020e-02, -4.0058e-02,\n",
      "         -9.1797e-03],\n",
      "        [-3.5497e-02,  6.0949e-02, -1.9896e-02, -1.3984e-01, -1.3588e-01,\n",
      "         -1.0580e-01],\n",
      "        [-1.7334e-01, -1.5135e-01,  1.4134e-01, -1.6814e-01, -1.5439e-01,\n",
      "          1.4208e-01],\n",
      "        [-9.0050e-02, -1.4231e-01,  1.0062e-01, -7.1108e-02, -1.9062e-01,\n",
      "         -1.9382e-01],\n",
      "        [ 2.3007e-02, -2.0454e-01, -1.2555e-01, -1.8226e-01, -1.5277e-01,\n",
      "          1.4606e-01],\n",
      "        [-4.6361e-01, -6.3047e-01, -6.5995e-01, -4.4894e-01, -7.8295e-01,\n",
      "         -7.1177e-01],\n",
      "        [-5.4477e-01, -7.5978e-01,  5.7633e-01, -6.1611e-01,  6.2129e-01,\n",
      "          3.7074e-01],\n",
      "        [-9.3947e-02, -1.8329e-01,  1.4265e-01, -1.0740e-01, -9.8187e-03,\n",
      "          3.0305e-03],\n",
      "        [-5.9528e-01, -6.0616e-01, -1.0735e+00, -7.6983e-01, -6.6050e-01,\n",
      "         -6.9935e-01],\n",
      "        [-5.2094e-01, -8.9976e-01, -9.8265e-01, -5.5281e-01, -5.5205e-01,\n",
      "         -6.3070e-01],\n",
      "        [-1.3785e-01,  1.0119e-01, -1.0213e-01,  6.0109e-02, -1.0371e-02,\n",
      "         -1.0805e-01],\n",
      "        [-1.5395e-01, -8.5983e-02, -1.7703e-01,  6.8787e-02,  2.3098e-02,\n",
      "          7.7375e-02],\n",
      "        [-4.5638e-02, -1.0273e-01, -1.5137e-01, -8.1461e-02, -1.6252e-01,\n",
      "          1.8388e-01],\n",
      "        [-1.4494e-01,  3.6831e-02,  1.4283e-01,  1.1949e-01, -8.3597e-02,\n",
      "         -1.0985e-01],\n",
      "        [-1.4346e-01,  2.9968e-03,  1.6179e-01, -5.0551e-02, -1.5603e-01,\n",
      "         -1.5860e-01],\n",
      "        [-4.8573e-01, -5.5511e-01, -5.9353e-01, -7.4444e-01,  6.3492e-01,\n",
      "         -7.6474e-01]], device='cuda:0')), ('ligand_conv2.bias', tensor([-0.5161, -0.5872, -0.9805, -0.6005, -0.5878, -0.6005, -0.4412, -0.9407,\n",
      "        -0.9477, -0.5955, -0.5138, -0.6551, -0.2420, -0.6841, -0.6005, -0.6005,\n",
      "        -0.6776, -0.6005, -0.6765, -0.4563, -0.6798, -0.5559, -0.6752, -0.4606,\n",
      "        -0.6121, -0.9968, -0.2761, -0.5554, -0.6005, -0.6005, -0.9970, -0.6852,\n",
      "        -0.6005, -0.5927, -0.7044, -0.9197, -0.6849, -0.6005, -0.5996, -1.0064,\n",
      "        -0.6694, -0.6735, -0.6005, -0.6634, -0.6675, -0.4563, -0.7727, -0.6004,\n",
      "        -0.6002, -0.8393, -0.6667, -0.6612, -0.9993, -0.5559, -0.7403, -0.6005,\n",
      "        -0.6951, -0.5966, -0.6735, -0.6849, -0.6932, -0.2571, -0.6687, -0.6004,\n",
      "        -0.5996, -0.6005, -0.6004, -1.0018, -0.6005, -1.0160, -0.6000, -0.1431,\n",
      "        -0.8980, -0.5125, -0.6002, -0.6001, -0.6871, -0.6004, -0.5774, -0.6749,\n",
      "        -0.6684, -0.6049, -0.2802, -0.6750, -0.6004, -0.6880, -0.6005, -0.9434,\n",
      "        -0.6005, -0.7547, -0.6004, -0.2944, -0.5558, -0.4574, -0.6005, -0.7106,\n",
      "        -0.6005, -0.6652, -0.5161, -0.6005, -1.0093, -0.9155, -0.9436, -0.6764,\n",
      "        -0.6482, -1.0016, -0.6002, -0.9854, -0.6902, -0.2428, -0.1169, -0.6657,\n",
      "        -0.6005, -0.6493, -0.4018, -0.4599, -1.1393, -0.6903, -0.6201, -0.6912,\n",
      "        -0.6158, -0.9640, -0.6005, -1.0226, -0.6002, -0.3085, -0.6882, -0.6885],\n",
      "       device='cuda:0')), ('ligand_conv2.lin.weight', tensor([[-0.0213, -0.0230,  0.0458,  ...,  0.1296,  0.1309,  0.0444],\n",
      "        [-0.0192,  0.0455, -0.0849,  ...,  0.0717,  0.1450,  0.7152],\n",
      "        [ 0.0830, -0.1419,  0.0537,  ..., -0.0090, -0.1117, -0.6420],\n",
      "        ...,\n",
      "        [-0.0532,  0.1400,  0.1489,  ...,  0.1515, -0.0592,  0.0875],\n",
      "        [ 0.0898, -0.0369,  0.1276,  ...,  0.1374, -0.1431,  0.6399],\n",
      "        [-0.0741,  0.1420, -0.1171,  ...,  0.1388,  0.0891,  0.6643]],\n",
      "       device='cuda:0')), ('protein_fc.weight', tensor([[-0.0251, -0.0426,  0.0246,  ...,  0.0816, -0.0807, -0.0246],\n",
      "        [-0.0442, -0.5780,  0.0444,  ...,  0.0197, -0.4720, -0.5518],\n",
      "        [ 0.0643,  0.0805,  0.0775,  ...,  0.0424,  0.0507,  0.0624],\n",
      "        ...,\n",
      "        [ 0.0518, -0.0794, -0.0505,  ...,  0.0597, -0.0875, -0.0864],\n",
      "        [ 0.0147,  0.5646,  0.0813,  ...,  0.0030,  0.4929,  0.0051],\n",
      "        [ 0.5995, -0.3806,  0.5484,  ...,  0.5738, -0.4553,  0.6491]],\n",
      "       device='cuda:0')), ('protein_fc.bias', tensor([-0.3855, -0.6426, -0.0763, -0.1916, -0.2590, -0.2205, -0.3633, -0.0571,\n",
      "        -0.2514, -0.5201, -0.5916, -0.6076, -0.5745, -0.5432, -0.0901, -0.5184,\n",
      "        -0.5688, -0.6156, -0.2415, -0.6104, -0.5125, -0.3760, -0.0715, -0.1229,\n",
      "        -0.0878, -0.5200, -0.4315, -0.5177, -0.2816, -0.1787, -0.5872, -0.2649,\n",
      "        -0.3779, -0.5691, -0.2777, -0.0711, -0.2215, -0.0825, -0.5431, -0.0664,\n",
      "        -0.6037, -0.0326, -0.3383, -0.0630, -0.0720, -0.5204, -0.0274, -0.2641,\n",
      "        -0.2755, -0.5686, -0.0366, -0.0304, -0.0538, -0.5144, -0.5417, -0.5726,\n",
      "        -0.5337, -0.5019, -0.5366, -0.5049, -0.6175, -0.0082, -0.1772, -0.0327,\n",
      "        -0.1581, -0.2389, -0.3654, -0.3325, -0.5214, -0.0473, -0.0330, -0.5860,\n",
      "        -0.2649, -0.5179, -0.5588, -0.0560, -0.2723, -0.6371, -0.0519, -0.3161,\n",
      "        -0.6434, -0.0179, -0.2519, -0.0494, -0.5357, -0.2538, -0.5993, -0.1870,\n",
      "        -0.0373, -0.6106, -0.0238, -0.1679, -0.2446, -0.0209, -0.3641, -0.1790,\n",
      "        -0.0350, -0.0494, -0.0763, -0.0082, -0.6008, -0.5022, -0.6096, -0.0575,\n",
      "        -0.0602, -0.5569, -0.5297, -0.2417, -0.5472, -0.5528, -0.5490, -0.2344,\n",
      "        -0.6028, -0.3302, -0.5994, -0.6166, -0.6253, -0.0203, -0.0757, -0.5725,\n",
      "        -0.0159, -0.6220, -0.5782, -0.5179, -0.5688, -0.0155, -0.5165, -0.1721],\n",
      "       device='cuda:0')), ('ligand_fc.weight', tensor([[ 0.5168,  0.4507, -0.0802,  ..., -0.0427,  0.5276,  0.5347],\n",
      "        [-0.5839,  0.2643, -0.0408,  ..., -0.4821,  0.2113,  0.1371],\n",
      "        [-0.0380, -0.4589,  0.6680,  ..., -0.6157, -0.3849, -0.4798],\n",
      "        ...,\n",
      "        [-0.0026, -0.4231,  0.5973,  ..., -0.6435, -0.3967, -0.4270],\n",
      "        [-0.0029, -0.5350,  0.6766,  ...,  0.4298, -0.4011, -0.5401],\n",
      "        [ 0.5494, -0.6478, -0.5606,  ..., -0.5186, -0.6792, -0.5146]],\n",
      "       device='cuda:0')), ('ligand_fc.bias', tensor([-0.4941, -0.3568, -0.4853, -0.6493, -0.7053, -0.6942, -0.5860, -0.7425,\n",
      "        -0.4272, -0.5268, -0.7482, -0.3864, -0.5336, -0.4354, -0.8333, -0.6578,\n",
      "        -0.5081, -0.2135, -0.0274, -0.4415, -0.5986, -0.4316, -0.7371, -0.6119,\n",
      "        -0.1924, -0.5740, -0.3673, -0.4180, -0.5923, -0.6339, -0.3816, -0.1223,\n",
      "        -0.7266, -0.4305, -0.7927, -0.4813, -0.2330, -0.4946, -0.5872, -0.4500,\n",
      "        -0.4973, -0.3685, -0.5676, -0.3560, -0.3618, -0.5024, -0.4734, -0.3989,\n",
      "        -0.0650, -0.5601, -0.5424, -0.7577, -0.7592, -0.4492, -0.5300, -0.3823,\n",
      "        -0.4101, -0.5753, -0.9576, -0.7786, -0.6218, -0.5181, -0.0629, -0.4417,\n",
      "        -0.4949, -0.3708, -0.4346, -0.4627, -0.3686, -0.7552, -0.5079, -0.4688,\n",
      "        -0.4362, -0.4455, -0.6056, -0.7352, -0.6939, -0.0714, -0.5315, -0.3843,\n",
      "        -0.5940, -0.5021, -0.4809, -0.2605, -0.7219, -0.6844, -0.5061, -0.6024,\n",
      "        -0.5440, -0.1302, -0.4099, -0.5127, -0.2667, -0.3261, -0.1170, -0.6247,\n",
      "        -0.5254, -1.0130, -0.5544, -0.1725, -0.7300, -0.3572, -0.8060, -0.0103,\n",
      "        -0.5529, -0.5700, -0.4899, -0.6697, -0.3906, -0.3002, -0.4718, -0.0399,\n",
      "        -0.4969, -0.5907, -0.4980, -0.4115, -0.3753, -0.7705, -0.3653, -0.6608,\n",
      "        -0.6609, -0.5675, -0.3796, -0.7572, -0.0040, -0.4833, -0.4709, -0.7180],\n",
      "       device='cuda:0')), ('final_fc.weight', tensor([[-4.9298e-01,  5.2799e-01,  4.8668e-02,  4.0050e-01, -2.8367e-01,\n",
      "          4.0786e-01,  4.1273e-01,  4.3958e-02,  4.2518e-01, -5.6489e-01,\n",
      "         -5.7609e-01,  5.7715e-01, -5.4174e-01, -5.8534e-01, -7.2844e-02,\n",
      "         -5.5165e-01, -5.9971e-01,  5.4964e-01,  4.1406e-01, -5.8271e-01,\n",
      "         -5.7604e-01,  2.1078e-01, -5.4070e-02, -2.4345e-01, -1.3707e-02,\n",
      "         -5.9053e-01, -1.0216e-01, -5.4860e-01,  4.3810e-01,  3.9630e-01,\n",
      "         -5.4317e-01,  4.3089e-01,  1.7378e-02, -5.6632e-01,  4.3364e-01,\n",
      "          6.0058e-03,  3.9151e-01, -3.5017e-02, -5.9722e-01,  4.6176e-02,\n",
      "         -5.9954e-01,  3.7837e-04,  4.0905e-01, -4.5731e-02,  3.5634e-02,\n",
      "         -4.1794e-01,  4.5292e-02,  4.3697e-01,  4.1431e-01, -5.4737e-01,\n",
      "         -1.5861e-02,  3.1821e-02,  1.7361e-02, -5.7876e-01, -5.8136e-01,\n",
      "         -5.4055e-01, -5.8713e-01,  4.6968e-01, -5.9698e-01, -2.0939e-03,\n",
      "          5.1304e-01, -4.8699e-02,  4.0020e-01, -1.6637e-01,  3.8085e-01,\n",
      "          4.3963e-01, -3.4279e-01, -1.6577e-01,  4.7130e-01,  1.1738e-02,\n",
      "          5.1686e-02, -5.4988e-01, -2.6974e-01, -5.6302e-01,  5.0156e-01,\n",
      "          9.9437e-03,  4.4198e-01,  5.4724e-01, -1.4421e-02, -2.1543e-01,\n",
      "          4.9508e-01,  5.5559e-02,  4.2126e-01,  3.1669e-02, -5.4602e-01,\n",
      "          3.8227e-01,  5.4741e-01,  3.9192e-01, -5.6689e-02, -5.9891e-01,\n",
      "         -4.7472e-02,  3.8676e-01,  4.1772e-01,  1.4326e-02, -1.6441e-01,\n",
      "         -7.6866e-02, -4.5909e-03,  2.0549e-02,  2.4141e-03,  6.0335e-02,\n",
      "         -5.9672e-01,  5.0860e-01,  5.2324e-01,  6.4594e-03,  6.2063e-02,\n",
      "          5.0395e-01, -5.8192e-01,  4.1641e-01, -5.3862e-01, -5.5242e-01,\n",
      "         -5.6675e-01,  4.0646e-01,  5.1200e-01,  1.4835e-01, -5.9777e-01,\n",
      "          5.1839e-01,  5.3524e-01,  3.2722e-02,  3.8334e-02, -5.9883e-01,\n",
      "         -2.5369e-02,  5.2095e-01, -5.6137e-01, -5.5676e-01, -5.7326e-01,\n",
      "          5.0132e-02,  4.2834e-01,  3.7893e-01,  3.9891e-01, -2.5085e-01,\n",
      "          4.0362e-01,  5.8458e-01,  3.4171e-01,  2.8388e-01,  5.1098e-01,\n",
      "          3.2748e-01,  4.2497e-01,  4.3673e-01,  3.4328e-01,  4.2144e-01,\n",
      "          4.4699e-01,  4.1671e-01,  7.9957e-02, -5.8500e-01, -4.7951e-01,\n",
      "         -3.1009e-01, -1.5330e-02,  4.3257e-01, -4.9450e-01,  4.0747e-01,\n",
      "          3.2207e-01,  5.0957e-01,  4.3517e-01,  3.5309e-01,  3.9289e-01,\n",
      "          4.0503e-01, -5.1748e-01,  5.9696e-01,  4.0567e-01, -4.1861e-01,\n",
      "          3.5231e-01,  4.1226e-01,  3.0303e-01, -4.8828e-01,  6.4997e-01,\n",
      "          4.1708e-01, -5.8086e-01,  4.4976e-01,  4.0628e-01,  4.2142e-01,\n",
      "          3.3628e-01,  4.0086e-01,  4.1878e-01, -4.2774e-01,  4.1500e-01,\n",
      "          3.9341e-01, -7.1447e-03,  3.4895e-01,  4.3295e-01,  3.5499e-01,\n",
      "          3.3198e-01,  4.3587e-01,  4.4151e-01,  4.4369e-01,  3.9752e-01,\n",
      "          4.8434e-01, -9.8335e-02,  3.4849e-01, -5.1298e-01,  4.4389e-01,\n",
      "          5.3155e-02, -3.3114e-01,  4.0012e-01,  4.5561e-01,  4.0804e-01,\n",
      "         -4.9847e-01,  4.5086e-01,  3.2972e-01,  4.3905e-01,  5.5314e-01,\n",
      "          4.0611e-01,  4.4828e-01,  4.3260e-01,  3.0224e-01,  3.1812e-01,\n",
      "         -7.1252e-03, -5.9469e-01,  4.4368e-01, -5.8010e-01, -5.1129e-01,\n",
      "         -5.0231e-01,  4.5166e-02,  2.9882e-01,  3.4741e-01, -4.1896e-01,\n",
      "          3.5153e-01,  5.2191e-01, -1.1667e-01,  4.2346e-01,  5.9658e-01,\n",
      "         -7.5988e-03, -3.5576e-01,  2.5459e-01,  3.2486e-01,  5.2049e-01,\n",
      "          5.7998e-03,  5.2964e-01, -5.7929e-02,  3.5848e-01,  4.1066e-01,\n",
      "          3.1719e-01,  8.1883e-03,  4.7037e-01,  5.5070e-01,  4.2703e-01,\n",
      "          3.0320e-01,  4.2526e-01,  4.1545e-01,  5.4887e-01,  5.6736e-02,\n",
      "          4.0103e-01,  4.7599e-01,  4.2585e-01,  4.1425e-01,  4.4248e-01,\n",
      "          3.0560e-01,  4.5131e-01,  3.2459e-01,  3.5844e-01,  4.9717e-01,\n",
      "          4.4074e-01,  3.6030e-01,  2.9460e-02,  4.0565e-01,  4.5402e-01,\n",
      "          3.4878e-01]], device='cuda:0')), ('final_fc.bias', tensor([-0.0032], device='cuda:0'))])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "\n",
    "protein_node_feats = 22\n",
    "smiles_node_feats = 6\n",
    "edge_feats = 4\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize the model\n",
    "model = ProteinLigandGCN(protein_node_feats, smiles_node_feats, hidden_dim, output_dim).to(device)\n",
    "# Load the model\n",
    "checkpoint = torch.load('best_model_24.pt')\n",
    "logger.info(f'keys in checkpoint: {checkpoint.keys()}')\n",
    "logger.info(f'model state dict: {checkpoint[\"odel_state_dict\"]}')\n",
    "model.load_state_dict(checkpoint['odel_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Prepare the test data\n",
    "# Assuming `test_dataset` is your dataset for test data\n",
    "test_data=ds.dataset(source=\"../../../data/test.parquet\", format=\"parquet\").to_table().to_pandas()\n",
    "\n",
    "test_loader =ProteinLigandDataset(test_data, protein_sequences)\n",
    "\n",
    "# Make predictions\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        protein_graph = batch['protein_graph'].to(device)\n",
    "        protein_features=protein_graph.x.to(device)\n",
    "        smiles_graph = batch['smiles_graph'].to(device)\n",
    "        smiles_features=smiles_graph.x.to(device)\n",
    "        label = batch['label']\n",
    "        output = model((protein_graph, protein_features), (smiles_graph, smiles_features))\n",
    "        #logger.info(f\"Predicted label for {label} is {output.squeeze(1).cpu().numpy()[0]}\")\n",
    "        predictions[label] = output.squeeze(1).cpu().numpy()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Save the predictions to a parquet file with the columns \"id\" and \"binds\"\n",
    "predictions_df = pd.DataFrame(predictions.items(), columns=[\"id\", \"binds\"])\n",
    "predictions_df.to_parquet(\"predictions.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295246830</td>\n",
       "      <td>0.499211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295246831</td>\n",
       "      <td>0.499211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295246832</td>\n",
       "      <td>0.499211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>295246833</td>\n",
       "      <td>0.499211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295246834</td>\n",
       "      <td>0.499211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     binds\n",
       "0  295246830  0.499211\n",
       "1  295246831  0.499211\n",
       "2  295246832  0.499211\n",
       "3  295246833  0.499211\n",
       "4  295246834  0.499211"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the predictions file\n",
    "predictions = pd.read_parquet(\"predictions.parquet\")\n",
    "import polars as pl\n",
    "\n",
    "pred=pl.read_parquet(\"predictions.parquet\")\n",
    "pred.head()\n",
    "#read the binds column and apply the sigmoid function to get the probability using torch.sigmoid\n",
    "predictions[\"binds\"]=torch.sigmoid(torch.tensor(predictions[\"binds\"].to_numpy())).numpy()\n",
    "predictions.head()\n",
    "\n",
    "#save the predictions to a parquet file\n",
    "predictions.to_parquet(\"predictions.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leash_bio_kaggle-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
